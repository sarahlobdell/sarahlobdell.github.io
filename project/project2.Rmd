---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Sarah Lobdell spl576"
date: '12/11/2020'
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---
```{r global_options, include=FALSE}
#LEAVE THIS CHUNK ALONE!
library(knitr)
opts_chunk$set(fig.align="center", fig.height=5, message=FALSE, warning=FALSE, fig.width=8, tidy.opts=list(width.cutoff=60),tidy=TRUE)

#HERE'S THE CLASSIFICAITON DIAGNOSTICS FUNCTION
class_diag<-function(probs,truth){
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  f1=2*(sens*ppv)/(sens+ppv)

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE){
    truth<-as.numeric(truth)-1}
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,f1,auc)
}
```

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

## Sarah Lobdell spl576

### Introduction

*The dataset I chose is called "Affairs." This dataset has information based on infidelity data collected from a survey carried out by Psychology Today in 1969. The data has 601 observations on 9 variables. The 9 variables include affairs, gender, age, years married, children, religiousness, education, occupation, and rating. Affairs is numeric in which an entry of 0 means there were no extramarital affairs, whereas any number greater has had at least 1 affair. Gender states whether the entry is a male or female. Age is the median age range in which that person falls; for example 17.5 is defined as someone under 20, while 22 codes for the range 20-24, 27 for 25-29, and so on. Years married measures the years the person has been married ranging from 3 months or less to 12 or more years. Children is a yes or no answer that states if the person has children. Religiousness measures how religious the person interviewed is, and education measures the amount of education that person has. Occupation measures whether the person has an occupation and to what extent, i.e, no occupation to professional level on the Hollingshead classification with reverse numbering. Lastly, rating measures the degree of happiness that person feels in the marriage, with 1 being very unhappy to 5 being very happy.* 
*In order to read the data, install.packages("AER") was first downloaded.*
```{r}
library(AER)
data("Affairs")
head(Affairs)
```

### Manova Testing
#### A MANOVA test was performed to test whether affairs, years married, religiousness, education, occupation, and rating differed by gender.
```{r}
man1<-manova(cbind(affairs, yearsmarried, religiousness, education, occupation, rating)~gender, data=Affairs)
summary(man1)
```
*The overall MANOVA was significant with a p value of 2.2e-16 showing a mean difference across gender. A follow-up one-way ANOVA and a univariate ANOVA was then ran to see which variables were significant.*
```{r}
summary.aov(man1)
Affairs%>%group_by(gender)%>%summarize(mean(education),mean(occupation))
```
*The follow-up one-way ANOVAs for each variable ran had two significant p values, both of 2.2e-16, for education and occupation. Both p values are significant for education and occupation meaning one gender differs. The univariate ANOVA showed a difference in means for education with females having a mean of 15.2571 (the range between some college and college graduate) and males having a mean of 17.1678 (the range between some graduate work and a masters degree). For the difference in means of occupation, women had a mean of 3.38413, and males had a mean of 5.08741 according to the Hollingshead classification. However, this is reverse numbering meaning women having a lower mean actually means their occupation is ranked higher/pays a higher salary, i.e, administrative personnel category vs skilled manual category for men.* 

####MANOVA assumptions:
```{r}
library(rstatix)

group <- Affairs$gender 
DVs <- Affairs %>% select(affairs, yearsmarried, religiousness, education, occupation, rating)
sapply(split(DVs,group), mshapiro_test)
```
*MANOVA assumptions include random samples of independent observations, multivariate normality of DVs, homogeneity of within-group covariance matrices, linear relationships among DVs, no extreme univarite or multivariate outliers, and no multicollinearity. Since p<.05, at least one assumption for MANOVA was violated.*

#### MANOVA Write-Up
*A one-way MANOVA was conducteed to determine the effect of gender on affairs, years married, religiousness, education, occupation, and rating. Examination of bivariate density plots for each group revealed no stark deparures from multivariate normality. Examination of covariance matrices for each group revealed relative homogeneity. No univariate or multivariate outliers were evident and MANOVA was considered to be an appropriate analysis technique.* 

*Significant differences were found among the two genders for at least one of the 6 dependent variables, Pillai trace = 0.25207, pseudo F (6, 594) = 33.366, p < 2.2e-16.* 

*Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA, using the Bonferroni method for controlling Type I error rates for multiple comparisons. The univariate ANOVAs for education and occupation were significant, F (1, 599) = 112.41, p < 2.2e-16, and F (1, 599) = 167.92, p < 2.2e-16, respectively. *

*Post-hoc t-tests were not needed since there are only 2 genders in our category, and we already know one differs. 1 MANOVA and 2 ANOVAs were performed, therefore a bonferroni Î± = .05/3 = 0.0167 should be used.*

*However, if there were more than 2 genders in the data, post-hoc analysis would be performed as such below, showing the same p value of p < 2.2e-16.:* 
```{r}
pairwise.t.test(Affairs$education, Affairs$gender, p.adj = "none")
pairwise.t.test(Affairs$occupation, Affairs$gender, p.adj = "none")
```

### Randomization Test for Mean Difference in Affairs by Gender 
```{r}
Affairs%>%group_by(gender)%>% summarize(mean=mean(affairs))%>%summarize(diff(mean))

rand_dist<-vector()
for(i in 1:5000){
  new<-data.frame(affairs=sample(Affairs$affairs),gender=Affairs$gender)
  rand_dist[i]<-mean(new[new$gender=="male",]$affairs)-
    mean(new[new$gender=="female",]$affairs)}

mean(rand_dist>0.0774559 | rand_dist < -0.0774559) 

t.test(data=Affairs,affairs~gender)
```

*The mean difference in number of affairs for two genders was performed. The actual observed test statistic/mean difference was calculated as 0.0774559. This was then randomized 5,000 times.*

*null hypothesis: mean number of affairs is the same for males and females*

*alternative hypothesis: mean number of affairs is different for males and females*

*The hand calculated p-value of 0.7696 corresponds to the probability of observing a mean difference as extreme as the one we got under this randomization distribution. An independent-samples t test was used for comparison and yeilded a p-value of 0.774. Both p values fail to reject the null hypothesis (the mean number of affairs is the same for males and females). *

#### Plot Visualizing the Null Distribution and the Test Statistic
```{r}
{hist(rand_dist,main="",ylab=""); abline(v = c(-0.07745, 0.07745),col="purple")}
```

### Linear Regression 
#### A linear regression model predicting the number of affairs from the interation of years married and gender was performed. 
```{r}
Affairs$yearsmarried_c <- Affairs$yearsmarried - mean(Affairs$yearsmarried)
fit<-lm(affairs ~ gender*yearsmarried_c, data=Affairs)
summary(fit)
```
*After mean centering years married, 1.4369 is the mean/predicted number of affairs for females with the average years married. For people with the average years married, males have an average/predicted number of affairs that is .040193 greater than females. The estimated slope for years married on the number of affairs for females is 0.111497 and the difference in slopes is -0.002099. *

#### The regression of the linear model was plotted. 
```{r}
ggplot(Affairs, aes(yearsmarried_c,affairs, color = gender)) + geom_smooth(method = "lm", se = F, fullrange = T)+ geom_point() 
```

#### Assumption of linearity, normality and homoskedacticity were checked. 

```{r}
resids<-fit$residuals; fitvals<-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, col="red")
library(lmtest)
library(sandwich)
bptest(fit)

ggplot()+geom_histogram(aes(resids),bins=20)
ggplot()+geom_qq(aes(sample=resids))+geom_qq_line()
```
*Assumptions were not met. This is shown graphically, as well as through the studentized Breusch-Pagan test that yeilded a p-value = 0.0001226. Since it is less than 0.05, we reject the null hypothesis that homoskedacticity is met.*

#### Recomputed Regression Results with Robust Standard Errors
```{r}
coeftest(lm(affairs ~ gender*yearsmarried_c, data=Affairs), vcov = vcovHC(lm(affairs ~ gender*yearsmarried_c, data=Affairs)))
```
*After recomputing the regression results with robust standard errors, 1.4369 remained as the mean/predicted number of affairs for females with the average years married with a significant p value of p = 5.192e-14. For people with the average years married, males also remained having an average/predicted number of affairs of 0.040193 greater than females with. However, the estimated slope for years married on the number of affairs for females changed from 0.111497 to 3.2996 with a significant p value = 0.001026, while the difference in slopes also changed from -0.002099 to -0.0444.*

*R squared says 3.495% of variability in affairs is explained by the overall model with both gender and years married predictors. While the adjusted R^2 is about the same at 3.01%, this is with penalty for each extra explanatory variable. *

### Bootstrapped Standard Errors by Resampling Residuals
*The same regression model was ran, and the bootstrapped standard errors by resampling residuals were computed.* 
```{r}
fit<-lm(affairs ~ gender*yearsmarried_c, data=Affairs)
  resids<-fit$residuals
  fitted<-fit$fitted.values
  resid_resamp<-replicate(5000,{
    new_resids<-sample(resids,replace=TRUE)
    newdat<-Affairs
    newdat$new_y<-fitted+new_resids
    fit<-lm(new_y ~ gender * yearsmarried_c, data = newdat)
    coef(fit)
})
resid_resamp%>%t%>%as.data.frame%>%summarize_all(sd)
resid_resamp%>%t%>%as.data.frame%>%pivot_longer(1:3)%>%group_by(name)%>%
 summarize(lower=quantile(value,.025), upper=quantile(value,.975))
```
#### Comparison (Regular SEs vs. Robust SEs vs. Bootstrapped SEs*
```{r}
coeftest(fit)[,1:2]
coeftest(fit, vcov=vcovHC(fit))[,1:2]
resid_resamp%>%t%>%as.data.frame%>%summarize_all(sd)
```

*As shown above, the standard errors all remained relatively the same. For the intercept, or the mean/predicted number of affairs for females with the average years married, the original standard error was 0.18312007, while the robust was 0.18631514, and the bootstrapped were 0.1833986. For the gendermale coefficient that predicted the number of affairs greater than females, the original standard error was 0.26546955, the robust was 0.26571144, and the bootstrapped was 0.2670994. The yearsmarried_c coefficient, or the estimated slope for years married on the number of affairs for females had an original standard error of 0.03258020, a robust of 0.03379133, and a bootstrapped of 0.0325755. Lastly, the gendermale:yearsmarried_c coefficient or the difference in slopes, had an original standard error of 0.04774633, a robust of 0.04728257, and a bootstrapped of 0.04758351. The changes in standard error for all comparisons were minimal, only changing after around the thousandths place.*

### Logistic Regression Predicting Affairs from Rating and Age
*For this logisitic regression, the variable "affairs" was turned into a binary variable, where 0 means no affair has happened and 1 means at least 1 affair has occurred.*
```{r}
AffairsData<-Affairs%>%mutate(affairs=ifelse(affairs=="0",0,1))
fit2<-glm(affairs~rating + age, family="binomial", data=AffairsData)
summary(fit2) 
exp(coef(fit2))
```
*The intercept for exp(coef(fit2)), shows the odds of an affair when rank and age are equal to 0 is 2.095. Controlling for age, for every additional rating point, odds of an affair occurring increase by a factor of 0.603 (significant). On the otherhand, controlling for age, for every one additional year of age, odds of an affair increase by a factor of 1.002 (not significant). *

#### Confusion Matrix
```{r}
probs2 <-predict(fit2,type="response") 
table(predict=as.numeric(probs2>.5),truth=AffairsData$affairs)%>%addmargins
```

#### Accuracy, Sensitivity (TPR), Specificity (TNR), Precision (PPV), and AUC of the model was computed: 
```{r}
class_diag(probs2, AffairsData$affairs)
```

*Accuracy was found to be 0.75 which is the proportion of correctly classified cases. Sensitivity, the true positive rate (TPR), was found to be 0.053; this shows the probability of predicting an affair if one actually occurred. Specificity, the true negative rate (TNR) or the proportion of non-affairs correctly classified, was found to be 0.982. Precision (PPV) was found to be 0.5 which is the proportion of those classified as affairs who actually are affairs. AUC was found to be 0.66225 which is considered a poor prediction model. *

#### Density Plot of Log-odds Grouped by Affairs
```{r}
AffairsData$affairs<-as.factor(AffairsData$affairs)
AffairsData$logit<-predict(fit2,type="link")
AffairsData%>%ggplot(aes(logit,color=affairs,fill=affairs))+geom_density(alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("predictor (logit)")
```

#### ROC Curve 
```{r}
AffairsData<-Affairs%>%mutate(affairs=ifelse(affairs=="0",0,1))
fit2<-glm(affairs~rating + age, family="binomial", data=AffairsData)
summary(fit2) 
exp(coef(fit2))
probs2 <-predict(fit2,type="response")

library(plotROC) 
ROCplot<-ggplot(AffairsData)+geom_roc(aes(d=affairs,m=probs2), n.cuts=0)
ROCplot
calc_auc(ROCplot)
```

*The ROC curve was generated and the AUC was calculated to be 0.66225 which is the same as what was calculated in the class diagnostics showing a poor prediction model. 

### Logistic Regression Predicting Affairs from All Variables
#### A logistic regression predicting affairs from all variables was performed.
```{r}
AffairsData<-Affairs%>%mutate(affairs=ifelse(affairs=="0",0,1))
library(tidyverse)
library(lmtest)
fit3 <- glm(affairs ~ ., data = AffairsData, family = "binomial")
summary(fit3)
coef(fit3)
exp(coef(fit3))
probs3 <-predict(fit3,type="response")
class_diag(probs3, AffairsData$affairs)
```
*Accuracy was found to be 0.765 which is the proportion of correctly classified cases. Sensitivity, the true positive rate (TPR), was found to be 0.167; this shows the probability of predicting an affair if one actually occurred. Specificity, the true negative rate (TNR) or the proportion of non-affairs correctly classified, was found to be 0.964. Precision (PPV) was found to be 0.609 which is the proportion of those classified as affairs who actually are affairs. AUC was found to be 0.712 which is considered a fair prediction model. *

*The intercept for exp(coef(fit3)), shows the odds of an affair for a female without kids when all other variables are equal to 0 is 3.96. Controlling for all other variables, when gender is male, odds of an affair occurring increase by a factor of 1.3235 (significant). Controlling for all other variables, for every one additional increase in age, odds of an affair increased by a factor of 0.9567 (significant). Controlling for all other variables, for every one additional year married, odds of an affair increased by 1.099 (significant). Controlling for all other variables, when a person has children odds of an affair increase by a factor of 1.488. Controlling for all other variables, when religiousness increases by an additional factor, odds of an affair increase by 0.7227 (significant). Controlling for all other variables, for every one additional increase in education, odds of an affair increase by 1.02127. Controlling for all other variables, for every one additional increase in occupation, odds of an affair increase by 1.0314. Controlling for all other variables, for every one additional increase in marriage rating, odds of an affair increase by 0.6259 (significant).*

####10-fold CV
```{r}
set.seed(1234)
k = 10
data <- AffairsData %>% sample_frac
folds <- ntile(1:nrow(data), n = 10)
diags <- NULL
for (i in 1:k) {
    train <- data[folds != i, ]
    test <- data[folds == i, ]
    truth <- test$affairs
    
    fit <- glm(affairs ~ ., data = train, family = "binomial")
    probs <- predict(fit, newdata = test, type = "response")
    diags <- rbind(diags, class_diag(probs, truth))
}
diags %>% summarize_all(mean)
```

*When a 10-fold CV was performed on the same model, the out-of-sample classification diagnostics differed slightly. Accuracy in the 10-fold sample decreased to 0.762 from the original 0.765. Sensitivity (TPR) also decreased to 0.166 from 0.167. Specificity (TNR) was 0.9647 which was small increase from the original at 0.9645. Precision decreased from 0.609 originally to 0.586, with the largest difference from the original class diagnostics of 0.023. Lastly, AUC also decreased from a fair model of 0.712 to a poor model with an AUC of 0.696 indicating overfitting.*

#### LASSO on the same model 
```{r}
library(glmnet)
set.seed(1234)

x <- model.matrix(affairs ~ ., data = AffairsData)[, -1]
x <- scale(x)
y <- as.matrix(AffairsData$affairs)

cv <- cv.glmnet(x, y, family = "binomial")
lasso <- glmnet(x, y, family = "binomial", lambda = cv$lambda.1se)
coef(lasso)
```
*LASSO was performed on the same model with all variables. The only variable retained was rating, meaning rating is the most predictive of affairs.*

#### 10-fold CV Using Only LASSO Selected Variable (rating)
```{r}
set.seed(1234)
k = 10
data <- AffairsData %>% sample_frac
folds <- ntile(1:nrow(data), n = 10)
diags <- NULL
for (i in 1:k) {
    train <- data[folds != i, ]
    test <- data[folds == i, ]
    truth <- test$affairs
    
    fit <- glm(affairs ~ rating, data = train, family = "binomial")
    probs <- predict(fit, newdata = test, type = "response")
    diags <- rbind(diags, class_diag(probs, truth))
}
diags %>% summarize_all(mean)
```

*Using only rating, this 10-fold CV model's out-of-sample AUC was 0.6523 which is deemed a poor prediction model. Compared to the original logistic regression that used all variables, this AUC is lower than the original's fair prediction model AUC of 0.712, indicating it is overfitting more and more. However, it is in the same AUC category at the 10-fold CV of the original model that used all variables with an AUC of 0.696. Both 10-fold CV models were poor prediction models and relatively similar. *
